{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  # provides interface for interacting with tabular data\n",
    "import geopandas as gpd  # combines the capabilities of pandas and shapely for geospatial operations\n",
    "from shapely.geometry import Point, Polygon, MultiPolygon  # for manipulating text data into geospatial shapes\n",
    "from shapely import wkt  # stands for \"well known text,\" allows for interchange across GIS programs\n",
    "import rtree  # supports geospatial join\n",
    "import os\n",
    "import fnmatch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import descartes\n",
    "import sys\n",
    "import sklearn\n",
    "import pandasql as ps\n",
    "from datetime import datetime as dt, timedelta, date\n",
    "sys.path.append('C:/Users/jades/1001 Intro to Data Science Notebooks/Project/wildfires-1001/code/functions/')\n",
    "from gis_processing import *\n",
    "\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the mapping df\n",
    "gitdir = 'C:/Users/jades/1001 Intro to Data Science Notebooks/Project/wildfires-1001/'\n",
    "\n",
    "subdir_from = 'data/clean_data/mapping_tables/'\n",
    "filename_from = 'grid_neighbor_map.csv'\n",
    "\n",
    "grid_neighbor_map = pd.read_csv(gitdir + subdir_from + filename_from)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import main df\n",
    "data_dir = 'C:/Users/jades/1001 Intro to Data Science Notebooks/Project/wildfires-1001/data'\n",
    "df_import = {}\n",
    "target_full = pd.DataFrame()\n",
    "for i in np.arange(1, 5):\n",
    "    df_import[i] = pd.read_pickle(os.path.join(data_dir, f'clean_data/target_full_{i}.pkl')) \n",
    "    target_full = target_full.append(df_import[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove unneeded columns and convert to a regular df\n",
    "target_full = pd.DataFrame(target_full[['date', 'month_id', 'GRID_ID', 'FIRE_KEY', 'YEAR', 'end_date']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create count of nearby grid fires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Y_bin'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2894\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2895\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2896\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Y_bin'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-155-ea80a5b048d7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Drop rows without fires\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtarget_clean\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtarget_full\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget_full\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtarget_full\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Y_bin'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2900\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2901\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2902\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2903\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2904\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2895\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2896\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2897\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2898\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2899\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Y_bin'"
     ]
    }
   ],
   "source": [
    "# Drop rows without fires\n",
    "target_clean = target_full.drop(target_full[target_full['Y_bin'] == 0].index, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select distinct month/grids\n",
    "q1 = \"\"\"SELECT DISTINCT month_id, GRID_ID FROM target_clean \"\"\"\n",
    "\n",
    "df_unique = ps.sqldf(q1, locals())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select distinct month/grids/fires\n",
    "q2 = \"\"\"SELECT DISTINCT month_id, GRID_ID, FIRE_KEY FROM target_clean \"\"\"\n",
    "\n",
    "df_unique_fires = ps.sqldf(q2, locals())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a new month key column that is the create month + 1 for joining purposes\n",
    "conditions = [\n",
    "    (df_unique.month_id.map(lambda x: x[5:]).astype(int) == 12),\n",
    "    (df_unique.month_id.map(lambda x: x[5:]).astype(int) != 12)\n",
    "    ]\n",
    "\n",
    "# Create a list of the values we want to assign for each condition\n",
    "values = [(df_unique.month_id.map(lambda x: x[:4]).astype(int)+1).astype(str) + '_1', \n",
    "          df_unique.month_id.map(lambda x: x[:4]) + '_' + (df_unique.month_id.map(lambda x: x[5:]).astype(int)+1).astype(str)]\n",
    "\n",
    "# Create a new column and use np.select to assign values to it using our lists as arguments\n",
    "df_unique['month_id_key'] = np.select(conditions, values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a new month key column that is the create month + 1 for joining purposes\n",
    "conditions = [\n",
    "    (df_unique_fires.month_id.map(lambda x: x[5:]).astype(int) == 12),\n",
    "    (df_unique_fires.month_id.map(lambda x: x[5:]).astype(int) != 12)\n",
    "    ]\n",
    "\n",
    "# Create a list of the values we want to assign for each condition\n",
    "values = [(df_unique_fires.month_id.map(lambda x: x[:4]).astype(int)+1).astype(str) + '_1', \n",
    "          df_unique_fires.month_id.map(lambda x: x[:4]) + '_' + (df_unique_fires.month_id.map(lambda x: x[5:]).astype(int)+1).astype(str)]\n",
    "\n",
    "# Create a new column and use np.select to assign values to it using our lists as arguments\n",
    "df_unique_fires['month_id_key'] = np.select(conditions, values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join on grid adj mapping\n",
    "df_merge = df_unique.merge(grid_neighbor_map, how='inner', left_on='GRID_ID', right_on='GRID_ID')\n",
    "\n",
    "#Join back to the fire count df joining grids with the counts from its neighbors\n",
    "df_merge = df_merge.merge(df_unique_fires, how='inner', left_on=('GRID_ID_adj', 'month_id'), right_on=('GRID_ID', 'month_id_key'))\n",
    "\n",
    "#Join back to the fire count df joining grids with the counts from its neighbors\n",
    "df_merge = df_merge.merge(df_unique_fires, how='left', left_on=('GRID_ID_x', 'month_id_x', 'FIRE_KEY'), right_on=('GRID_ID', 'month_id', 'FIRE_KEY'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the adjacent fires by central grid and month\n",
    "# Sum the multiplier column rather than doing a count to adjust for central grids on the edge\n",
    "df_features = df_merge[['month_id_x', 'GRID_ID_x', 'multiplier']].groupby(['month_id_x', 'GRID_ID_x']).sum().reset_index()\n",
    "\n",
    "# Create a column for the binary flag\n",
    "df_features['adj_fire_bcount'] = 1\n",
    "\n",
    "# Clean up the df\n",
    "df_features = df_features.rename(columns={'month_id_x': 'month_id', 'GRID_ID_x': 'GRID_ID', 'multiplier': 'adj_fire_count'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rejoin New Features to the Main DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select distinct month/grids\n",
    "q3 = \"\"\"SELECT DISTINCT month_id, GRID_ID FROM target_full \"\"\"\n",
    "\n",
    "df_final = ps.sqldf(q3, locals())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do a left join of the features onto the main DF\n",
    "df_final = df_final.merge(df_features, how='left', on=('GRID_ID', 'month_id'))\n",
    "\n",
    "# Fill any NAs (places without fires) with 0s\n",
    "df_final = df_final['adj_fire_count'].fillna(0)\n",
    "df_final = df_final['adj_fire_bcount'].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the clean df\n",
    "subdir_to = 'data/clean_data/engineered_features/'\n",
    "filename_to = 'adj_fire_final.csv'\n",
    "df_final.to_csv(gitdir + subdir_to + filename_to, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
