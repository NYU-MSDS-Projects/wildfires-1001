{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pull in the main fire dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages\n",
    "import pandas as pd  # provides interface for interacting with tabular data\n",
    "import geopandas as gpd  # combines the capabilities of pandas and shapely for geospatial operations\n",
    "import rtree  # supports geospatial join\n",
    "import os\n",
    "import fnmatch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import pickle\n",
    "from shapely.ops import nearest_points\n",
    "from datetime import datetime as dt, date\n",
    "sys.path.append('/Users/jackepstein/Documents/GitHub/wildfires-1001/code/functions/')\n",
    "data_dir = '/Users/jackepstein/Documents/GitHub/wildfires-1001/data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in the target variables for fire\n",
    "target_df = {}\n",
    "full_target_data = gpd.GeoDataFrame()\n",
    "for i in np.arange(1, 4):\n",
    "    target_df[i] = pd.read_pickle(os.path.join(data_dir, f'clean_data/target_full_{i}.pkl')) \n",
    "    full_target_data = full_target_data.append(target_df[i])\n",
    "    \n",
    "#change data types\n",
    "full_target_data['COUNTYFP'] = full_target_data['COUNTYFP'].astype(int)\n",
    "full_target_data['GRID_ID'] = full_target_data['GRID_ID'].astype(int)\n",
    "full_target_data['YEAR'] = full_target_data['date'].apply(lambda x:x.year)  \n",
    "full_target_data['MONTH'] = full_target_data['date'].apply(lambda x:x.month)  \n",
    "\n",
    "#drop unneeded columns\n",
    "full_target_data2 = full_target_data.drop(columns=['date','month_start', 'month_end', 'week_id',\n",
    "                                                  'week_start', 'week_end', 'start_date', 'end_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking what one instance will look like\n",
    "#full_target_data2.loc[full_target_data2['GRID_ID']==36].loc[full_target_data2['month_id']=='2018_11']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial Group By"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#group by gridid and month and take means of fire data\n",
    "#y_bin, y_fire_class_size -- take max\n",
    "#y_fire_count -- count distinct of FIRE ID\n",
    "#y_fire_area prop -- done below with a separate dissolve and join rather than groupby \n",
    "target_data_month = full_target_data2.groupby(['GRID_ID','month_id','YEAR', 'MONTH','COUNTYFP','NAME', 'GRID_AREA', \n",
    "                                               'COUNTY_ARE']).agg({'Y_bin':'max', \n",
    "                                                                   'Y_fire_class_size': 'max',\n",
    "                                                                   'FIRE_KEY':'nunique'}).reset_index()\n",
    "target_data_month = target_data_month.rename(columns={'FIRE_KEY': 'Y_fire_count'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DO NOT RE-RUN UNLESS NEEDED VERY SLOW\n",
    "#make a new DF with just needed columns\n",
    "sub_geo_df = full_target_data2[['month_id', 'GRID_ID', 'geometry']]\n",
    "#sub_geo_df.loc[sub_geo_df['GRID_ID']==36].loc[sub_geo_df['month_id']=='2018_11']\n",
    "\n",
    "#only positive instances\n",
    "sub_geo_df_2 = sub_geo_df.loc[~sub_geo_df['geometry'].isna()]\n",
    "\n",
    "#dissolve\n",
    "sub_geo_dissolve = sub_geo_df_2.dissolve(by=['GRID_ID','month_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reset the index and calcuate area\n",
    "sub_geo_dissolve = sub_geo_dissolve.reset_index()\n",
    "sub_geo_dissolve['Fire_area'] = sub_geo_dissolve['geometry'].area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge grouped by df with dissolved df\n",
    "target_data_month = target_data_month.merge(sub_geo_dissolve, on=['GRID_ID','month_id'], how='left')\n",
    "#replace NaN in Fire_area with 0\n",
    "target_data_month['Fire_area'] = target_data_month['Fire_area'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate target variable for regression\n",
    "target_data_month['Y_fire_area_prop'] = target_data_month['Fire_area']/target_data_month['GRID_AREA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop grid ID 59 -- no weather data\n",
    "target_data_month_df = target_data_month.loc[target_data_month['GRID_ID']!=59]\n",
    "#check for positive instances\n",
    "#target_data_month_df.loc[target_data_month_df['Y_bin']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#take in an object formatted as YYYY_MM\n",
    "def add_one_month(month_id_obj):\n",
    "    \n",
    "    #turn this object into a string\n",
    "    #split this and take the element after the '_'\n",
    "    #turn this back into an int\n",
    "    month_int = int(str(month_id_obj).split('_')[1])\n",
    "    year_int = int(str(month_id_obj).split('_')[0])\n",
    "    \n",
    "    #check if the month is decemember -- if so, set to 1 if not, add one\n",
    "    if month_int == 12:\n",
    "        mont = 1\n",
    "        new_month_id = str(year_int+1)+'_'+str(mont)\n",
    "    else:\n",
    "        mont = int(month_int+1)\n",
    "        new_month_id = str(year_int)+'_'+str(mont)\n",
    "        \n",
    "    return new_month_id    \n",
    "    \n",
    "#take in an object formatted as YYYY_MM\n",
    "def sub_one_month(month_id_obj):\n",
    "    \n",
    "    #turn this object into a string\n",
    "    #split this and take the element after the '_'\n",
    "    #turn this back into an int\n",
    "    month_int = int(str(month_id_obj).split('_')[1])\n",
    "    year_int = int(str(month_id_obj).split('_')[0])\n",
    "    \n",
    "    #check if the month is janary -- if so, set to 12 if not, subtract one\n",
    "    if month_int == 1:\n",
    "        mont = 12\n",
    "        new_month_id = str(year_int-1)+'_'+str(mont)\n",
    "    else:\n",
    "        mont = int(month_int-1)\n",
    "        new_month_id = str(year_int)+'_'+str(mont)\n",
    "        \n",
    "    return new_month_id  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pull in the other simpler data sets (demogs, arson, topo, infr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#topography\n",
    "#no need to shift -- no month ids\n",
    "topo_df = pd.read_csv(os.path.join(data_dir, 'clean_data/topography/grid_elevation.csv'))\n",
    "topo_df['GRID_ID'] = topo_df['GRID_ID'].astype(int)\n",
    "topo_df = topo_df.drop(columns=topo_df.columns[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#infrastructure\n",
    "#shift month up 1\n",
    "infr_df = pd.read_csv((os.path.join(data_dir, 'clean_data/grid_infrastructure/grid_infrastructure_monthly.csv')))\n",
    "infr_df['GRID_ID'] = infr_df['GRID_ID'].astype(int)\n",
    "infr_df['month_id_old'] = infr_df['month_id']\n",
    "infr_df['month_id'] = infr_df['month_id'].apply(lambda x: add_one_month(x))\n",
    "infr_df = infr_df.drop(columns=infr_df.columns[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#demographics\n",
    "#shift up a year\n",
    "demographics_df = pd.read_csv((os.path.join(data_dir, 'clean_data/ca_demogs/demogs_arson_master.csv')))\n",
    "demographics_df['YEAR'] = demographics_df['YEAR']+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pull in built fire features\n",
    "#no need to shift\n",
    "fire_feat = pd.read_csv((os.path.join(data_dir, 'clean_data/engineered_features/adj_fire_final.csv')))\n",
    "fire_feat['GRID_ID'] = fire_feat['GRID_ID'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge with these"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge with topo\n",
    "target_data_month_df = target_data_month_df.merge(topo_df, on='GRID_ID', how='left')\n",
    "\n",
    "#merge with infrastructure\n",
    "target_data_month_df = target_data_month_df.merge(infr_df, on=['GRID_ID','month_id'], how='left')\n",
    "\n",
    "#merge with demographics\n",
    "target_data_month_df = target_data_month_df.merge(demographics_df, on=['GRID_ID', 'NAME', 'COUNTYFP', 'YEAR'], how='left')\n",
    "\n",
    "#merge with other fire\n",
    "target_data_month_df = target_data_month_df.merge(fire_feat, on=['GRID_ID','month_id'], how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pull in and merge with weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#weather \n",
    "era_weather = pd.read_pickle((os.path.join(data_dir, 'clean_data/ERA_weather-data/ERA5_CAgrid_gdf.pkl')))\n",
    "era_weather['GRID_ID'] = era_weather['GRID_ID'].astype(int)\n",
    "\n",
    "\n",
    "#add in a month_id column\n",
    "#need to shift up a month\n",
    "era_weather['month'] = pd.DatetimeIndex(era_weather['date']).month\n",
    "era_weather['YEAR'] = pd.DatetimeIndex(era_weather['date']).year\n",
    "era_weather['month_id'] = era_weather['YEAR'].astype(str)+'_'+era_weather['month'].astype(str)\n",
    "era_weather['month_id_old'] = era_weather['month_id']\n",
    "era_weather['month_id'] = era_weather['month_id'].apply(lambda x: add_one_month(x))\n",
    "era_weather = era_weather.drop(columns=['date','month','YEAR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge weather\n",
    "target_data_month_df = target_data_month_df.merge(era_weather, on=['GRID_ID','month_id'], how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge with additional fire and weather features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in historical features - no need to shift\n",
    "fire_hist = pd.read_pickle((os.path.join(data_dir, 'clean_data/engineered_features/fire_hist_features.pkl')))\n",
    "fire_hist['GRID_ID'] = fire_hist['GRID_ID'].astype(int)\n",
    "fire_hist = fire_hist.rename(columns={'month': 'MONTH', 'year':'YEAR'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge with main df\n",
    "target_data_month_df = target_data_month_df.merge(fire_hist, on=['GRID_ID','month_id', 'MONTH', 'YEAR'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in engineered weather - no need to shift\n",
    "#read in historical features - no need to shift\n",
    "weather_hist = pd.read_pickle((os.path.join(data_dir, 'clean_data/engineered_features/historical_weather.pkl')))\n",
    "weather_hist = weather_hist.rename(columns={'month': 'MONTH', 'year':'YEAR'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge with main df\n",
    "target_data_month_df = target_data_month_df.merge(weather_hist, on=['GRID_ID', 'MONTH', 'YEAR'], how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Clean Up and Send to Pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping jan 1990 with no weather data from the previous month\n",
    "target_df_final = target_data_month_df.loc[target_data_month_df['month_id']!='1990_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#re-read in county grid to join with geometry\n",
    "county_grid = gpd.read_file(os.path.join(data_dir, 'clean_data/county_grid/county_grid.dbf'))\n",
    "county_grid['GRID_ID'] = county_grid['GRID_ID'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge this with the initial df to get geometry\n",
    "target_df_final_geo = target_df_final.merge(county_grid[['GRID_ID','geometry']], on='GRID_ID', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the naming dictionary\n",
    "weather_dict_path = os.path.join(data_dir, 'clean_data/ERA_weather-data/ERA_rename_dictionary.pkl')\n",
    "with open(weather_dict_path, 'rb') as handle:\n",
    "    rename_dict = pickle.load(handle)\n",
    "    \n",
    "#rename the columns based on this dictionary\n",
    "target_df_final_geo.rename(columns = rename_dict, inplace = True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#functions to check if we have _x or _y\n",
    "def find_x(col_name):\n",
    "    if col_name.find('_x') == -1:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "    \n",
    "def find_y(col_name):\n",
    "    if col_name.find('_y') == -1:\n",
    "        return False\n",
    "    else:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for _x, remove the _x\n",
    "#for _y, drop that column\n",
    "\n",
    "#run through all the column names\n",
    "for j in target_df_final_geo.columns:\n",
    "    #if we have an _x, change the name\n",
    "    if find_x(j):\n",
    "        j_new = j.replace('_x', '')\n",
    "        target_df_final_geo[j_new] = target_df_final_geo[j]\n",
    "        target_df_final_geo = target_df_final_geo.drop(columns=[j])\n",
    "    \n",
    "    #if we have a y, drop this columns\n",
    "    if find_y(j):\n",
    "        target_df_final_geo = target_df_final_geo.drop(columns=[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "192\n",
      "GRID_ID\n",
      "month_id\n",
      "YEAR\n",
      "MONTH\n",
      "COUNTYFP\n",
      "NAME\n",
      "GRID_AREA\n",
      "COUNTY_ARE\n",
      "Y_bin\n",
      "Y_fire_count\n",
      "Fire_area\n",
      "elev_mean\n",
      "elev_std\n",
      "elev_media\n",
      "elev_max\n",
      "elev_min\n",
      "elev_range\n",
      "pl_count\n",
      "total_pl_length\n",
      "road_count\n",
      "total_road_length\n",
      "MEDIAN_AGE_TOT\n",
      "MEDIAN_AGE_MALE\n",
      "MEDIAN_AGE_FEM\n",
      "AGEUNDER13_TOT\n",
      "AGE1424_TOT\n",
      "AGE2544_TOT\n",
      "AGE4564_TOT\n",
      "AGE65PLUS_TOT\n",
      "COUNTY_AREA\n",
      "POPDENSITY\n",
      "POPDENSITY_MALE\n",
      "POPDENSITY_FEM\n",
      "Structure Arsons\n",
      "Mobile Arsons\n",
      "Other Arsons\n",
      "Total Arsons\n",
      "Total Arsons Cleared\n",
      "Unemployment\n",
      "medianHHI2018\n",
      "adj_fire_count\n",
      "adj_fire_bcount\n",
      "U_wind_10m_0hrs\n",
      "V_wind_10m_0hrs\n",
      "2m_dewpoint_tmp_0hrs\n",
      "2m_tmp_0hrs\n",
      "leaf_high_veg_0hrs\n",
      "leaf_low_veg_0hrs\n",
      "surface_pressure_0hrs\n",
      "tot_prcp_0hrs\n",
      "U_wind_10m_6hrs\n",
      "V_wind_10m_6hrs\n",
      "2m_dewpoint_tmp_6hrs\n",
      "2m_tmp_6hrs\n",
      "leaf_high_veg_6hrs\n",
      "leaf_low_veg_6hrs\n",
      "surface_pressure_6hrs\n",
      "tot_prcp_6hrs\n",
      "U_wind_10m_12hrs\n",
      "V_wind_10m_12hrs\n",
      "2m_dewpoint_tmp_12hrs\n",
      "2m_tmp_12hrs\n",
      "leaf_high_veg_12hrs\n",
      "leaf_low_veg_12hrs\n",
      "surface_pressure_12hrs\n",
      "tot_prcp_12hrs\n",
      "U_wind_10m_18hrs\n",
      "V_wind_10m_18hrs\n",
      "2m_dewpoint_tmp_18hrs\n",
      "2m_tmp_18hrs\n",
      "leaf_high_veg_18hrs\n",
      "leaf_low_veg_18hrs\n",
      "surface_pressure_18hrs\n",
      "tot_prcp_18hrs\n",
      "hist_bin_1m\n",
      "hist_bin_1y\n",
      "hist_bin_5y\n",
      "hist_bin_10y\n",
      "Y_fire_class_size_prev_month\n",
      "Y_fire_class_size_prev_1yr\n",
      "Y_fire_class_size_prev_5yr\n",
      "Y_fire_class_size_prev_10yr\n",
      "Y_fire_area_prop_prev_month\n",
      "Y_fire_area_prop_prev_1yr\n",
      "Y_fire_area_prop_prev_5yr\n",
      "Y_fire_area_prop_prev_10yr\n",
      "hist_p_time_1m\n",
      "total_fire_days\n",
      "hist_p_time_1y\n",
      "total_fire_days\n",
      "hist_p_time_1y\n",
      "tot_area_fire_prev_1yr\n",
      "U_wind_10m_0hrs_1y\n",
      "U_wind_10m_6hrs_1y\n",
      "U_wind_10m_12hrs_1y\n",
      "U_wind_10m_18hrs_1y\n",
      "V_wind_10m_0hrs_1y\n",
      "V_wind_10m_6hrs_1y\n",
      "V_wind_10m_12hrs_1y\n",
      "V_wind_10m_18hrs_1y\n",
      "2m_dewpoint_tmp_0hrs_1y\n",
      "2m_dewpoint_tmp_6hrs_1y\n",
      "2m_dewpoint_tmp_12hrs_1y\n",
      "2m_dewpoint_tmp_18hrs_1y\n",
      "2m_tmp_0hrs_1y\n",
      "2m_tmp_6hrs_1y\n",
      "2m_tmp_12hrs_1y\n",
      "2m_tmp_18hrs_1y\n",
      "leaf_high_veg_0hrs_1y\n",
      "leaf_high_veg_6hrs_1y\n",
      "leaf_high_veg_12hrs_1y\n",
      "leaf_high_veg_18hrs_1y\n",
      "leaf_low_veg_0hrs_1y\n",
      "leaf_low_veg_6hrs_1y\n",
      "leaf_low_veg_12hrs_1y\n",
      "leaf_low_veg_18hrs_1y\n",
      "surface_pressure_0hrs_1y\n",
      "surface_pressure_6hrs_1y\n",
      "surface_pressure_12hrs_1y\n",
      "surface_pressure_18hrs_1y\n",
      "tot_prcp_0hrs_1y\n",
      "tot_prcp_6hrs_1y\n",
      "tot_prcp_12hrs_1y\n",
      "tot_prcp_18hrs_1y\n",
      "U_wind_10m_0hrs_5y\n",
      "U_wind_10m_6hrs_5y\n",
      "U_wind_10m_12hrs_5y\n",
      "U_wind_10m_18hrs_5y\n",
      "V_wind_10m_0hrs_5y\n",
      "V_wind_10m_6hrs_5y\n",
      "V_wind_10m_12hrs_5y\n",
      "V_wind_10m_18hrs_5y\n",
      "2m_dewpoint_tmp_0hrs_5y\n",
      "2m_dewpoint_tmp_6hrs_5y\n",
      "2m_dewpoint_tmp_12hrs_5y\n",
      "2m_dewpoint_tmp_18hrs_5y\n",
      "2m_tmp_0hrs_5y\n",
      "2m_tmp_6hrs_5y\n",
      "2m_tmp_12hrs_5y\n",
      "2m_tmp_18hrs_5y\n",
      "leaf_high_veg_0hrs_5y\n",
      "leaf_high_veg_6hrs_5y\n",
      "leaf_high_veg_12hrs_5y\n",
      "leaf_high_veg_18hrs_5y\n",
      "leaf_low_veg_0hrs_5y\n",
      "leaf_low_veg_6hrs_5y\n",
      "leaf_low_veg_12hrs_5y\n",
      "leaf_low_veg_18hrs_5y\n",
      "surface_pressure_0hrs_5y\n",
      "surface_pressure_6hrs_5y\n",
      "surface_pressure_12hrs_5y\n",
      "surface_pressure_18hrs_5y\n",
      "tot_prcp_0hrs_5y\n",
      "tot_prcp_6hrs_5y\n",
      "tot_prcp_12hrs_5y\n",
      "tot_prcp_18hrs_5y\n",
      "U_wind_10m_0hrs_10y\n",
      "U_wind_10m_6hrs_10y\n",
      "U_wind_10m_12hrs_10y\n",
      "U_wind_10m_18hrs_10y\n",
      "V_wind_10m_0hrs_10y\n",
      "V_wind_10m_6hrs_10y\n",
      "V_wind_10m_12hrs_10y\n",
      "V_wind_10m_18hrs_10y\n",
      "2m_dewpoint_tmp_0hrs_10y\n",
      "2m_dewpoint_tmp_6hrs_10y\n",
      "2m_dewpoint_tmp_12hrs_10y\n",
      "2m_dewpoint_tmp_18hrs_10y\n",
      "2m_tmp_0hrs_10y\n",
      "2m_tmp_6hrs_10y\n",
      "2m_tmp_12hrs_10y\n",
      "2m_tmp_18hrs_10y\n",
      "leaf_high_veg_0hrs_10y\n",
      "leaf_high_veg_6hrs_10y\n",
      "leaf_high_veg_12hrs_10y\n",
      "leaf_high_veg_18hrs_10y\n",
      "leaf_low_veg_0hrs_10y\n",
      "leaf_low_veg_6hrs_10y\n",
      "leaf_low_veg_12hrs_10y\n",
      "leaf_low_veg_18hrs_10y\n",
      "surface_pressure_0hrs_10y\n",
      "surface_pressure_6hrs_10y\n",
      "surface_pressure_12hrs_10y\n",
      "surface_pressure_18hrs_10y\n",
      "tot_prcp_0hrs_10y\n",
      "tot_prcp_6hrs_10y\n",
      "tot_prcp_12hrs_10y\n",
      "tot_prcp_18hrs_10y\n",
      "Y_fire_class_size\n",
      "geometry\n",
      "Y_fire_area_prop\n",
      "month_id_old\n"
     ]
    }
   ],
   "source": [
    "#check we have the correct columns\n",
    "print(target_df_final_geo.columns.size)\n",
    "for k in target_df_final_geo.columns:\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#send to pkl files -- remember to rename the file and update date\n",
    "#need to split to allow to push to git\n",
    "n_rows = np.round(len(target_df_final_geo)/2,0).astype(int)\n",
    "target_df_final_geo.iloc[:n_rows].to_pickle(os.path.join(data_dir, 'clean_data/target_df_final_geo_1121_weathereng_1.pkl'))\n",
    "target_df_final_geo.iloc[n_rows:].to_pickle(os.path.join(data_dir, 'clean_data/target_df_final_geo_1121_weathereng_2.pkl'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
