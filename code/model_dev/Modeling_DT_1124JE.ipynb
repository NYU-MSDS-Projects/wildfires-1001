{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score, roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages\n",
    "import pandas as pd  # provides interface for interacting with tabular data\n",
    "import geopandas as gpd  # combines the capabilities of pandas and shapely for geospatial operations\n",
    "import rtree  # supports geospatial join\n",
    "import os\n",
    "import fnmatch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import pickle\n",
    "from shapely.ops import nearest_points\n",
    "from datetime import datetime as dt, date\n",
    "sys.path.append('/Users/jackepstein/Documents/GitHub/wildfires-1001/code/functions/')\n",
    "data_dir = '/Users/jackepstein/Documents/GitHub/wildfires-1001/data'\n",
    "code_dir = '/Users/jackepstein/Documents/GitHub/wildfires-1001/code'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pull in main data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pull in the target data frame and weather dictionary \n",
    "#make sure to change the pkl file name if needed\n",
    "target_dict = {}\n",
    "target_df = gpd.GeoDataFrame()\n",
    "for i in np.arange(1, 3):\n",
    "    target_dict[i] = pd.read_pickle(os.path.join(data_dir, f'clean_data/target_df_final_1123_newtargets_{i}.pkl')) \n",
    "    target_df = target_df.append(target_dict[i])\n",
    "\n",
    "\n",
    "weather_dict_path = os.path.join(data_dir, 'clean_data/ERA_weather-data/ERA_rename_dictionary.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the naming dictionary\n",
    "with open(weather_dict_path, 'rb') as handle:\n",
    "    rename_dict = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename the columns based on this dictionary\n",
    "target_df.rename(columns = rename_dict, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create lists of columns to drop and what our targets are\n",
    "non_mod_cols = ['GRID_ID','month_id','MONTH','COUNTYFP','NAME','GRID_AREA','COUNTY_ARE','COUNTY_AREA',\n",
    "                'geometry', 'adj_fire_count','adj_fire_bcount', 'Fire_area','Index','index']\n",
    "bad_features = ['hist_p_time_1m', 'total_fire_days', 'hist_p_time_1y','month_id_old']\n",
    "Y_cols = ['Y_bin', 'Y_fire_count', 'Y_fire_area_prop', 'Y_fire_class_size','Y_bin_new_fire_month',\n",
    "          'Y_max_new_fire_size_month','Y_count_new_fires_month']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_feats_rf = ['tot_area_fire_prev_1yr','2m_tmp_18hrs_5y','hist_fire_area_prop_1y','2m_tmp_18hrs_10y',\n",
    "             '2m_tmp_18hrs_1y','hist_prop_area_fire_1m','2m_tmp_0hrs_5y','hist_fire_area_prop_1m',\n",
    "             'tot_prcp_12hrs_10y','tot_prcp_6hrs_10y','hist_fire_area_prop_5y','2m_tmp_0hrs_1y','2m_tmp_0hrs_10y',\n",
    "             'hist_fire_area_prop_10y','tot_prcp_18hrs_10y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert floats from 64 to 32 for model\n",
    "for col in target_df.columns:\n",
    "    if target_df[col].dtypes == 'float64':\n",
    "        target_df[col] = target_df[col].astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate training data set\n",
    "#pre 2016\n",
    "train_data = target_df[target_df['YEAR']<2016]\n",
    "X_train = train_data.drop('YEAR', axis = 1)\n",
    "#drop columns not used for modeling\n",
    "for y in Y_cols + non_mod_cols + bad_features:\n",
    "    try:\n",
    "        X_train.drop(y, inplace = True, axis =1)\n",
    "    except:\n",
    "        pass\n",
    "#set up target variable\n",
    "Y_train_reg = train_data[['Y_fire_area_prop']]\n",
    "Y_train_cl = train_data[['Y_bin_new_fire_month']]\n",
    "Y_train_cl_size = train_data[['Y_max_new_fire_size_month']]\n",
    "\n",
    "#generate testing data set - same logic as above\n",
    "test_data = target_df[target_df['YEAR']>=2016]\n",
    "X_test = test_data.drop('YEAR', axis = 1)\n",
    "for y in Y_cols + non_mod_cols + bad_features:\n",
    "    try:\n",
    "        X_test.drop(y, inplace = True, axis =1)\n",
    "    except:\n",
    "        pass\n",
    "Y_test_reg = test_data[['Y_fire_area_prop']]\n",
    "Y_test_cl = test_data[['Y_bin_new_fire_month']]\n",
    "Y_test_cl_size = test_data[['Y_max_new_fire_size_month']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check for any null values\n",
    "\n",
    "#null vals array\n",
    "null = np.zeros(len(X_train.columns))\n",
    "\n",
    "for i in range(len(X_train.columns)):\n",
    "    null[i] = X_train.loc[X_train[X_train.columns[i]].isna()].shape[0]\n",
    "    \n",
    "np.sum(null)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Decision Tree -- baseline: OOB all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(criterion='entropy')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#run tree\n",
    "dt_clf_bl = DecisionTreeClassifier(criterion='entropy')\n",
    "dt_clf_bl.fit(X_train, Y_train_cl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6022115000486431\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.90      0.90      5553\n",
      "           1       0.30      0.31      0.30       783\n",
      "\n",
      "    accuracy                           0.82      6336\n",
      "   macro avg       0.60      0.60      0.60      6336\n",
      "weighted avg       0.83      0.82      0.83      6336\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#get arrays\n",
    "y_true = Y_test_cl.to_numpy().ravel()\n",
    "y_preds_bl = dt_clf_bl.predict(X_test)\n",
    "y_preds_prob_bl = dt_clf_bl.predict_proba(X_test)\n",
    "\n",
    "print(roc_auc_score(y_true, y_preds_bl))\n",
    "\n",
    "print(classification_report(y_true, y_preds_bl))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Decisiont Tree - hyperparameter tuning, all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 4, 8, 16, 32, 64, 128, 256, 512, 1024]\n",
      "[16, 32, 64, 128, 256, 512, 1024, 2048]\n"
     ]
    }
   ],
   "source": [
    "#generate lists of hyper params\n",
    "leaf_base = 2\n",
    "min_samples_leaf_values = []\n",
    "for l in range(1,11):\n",
    "    min_samples_leaf_values.append(leaf_base**l)\n",
    "print(min_samples_leaf_values)\n",
    "\n",
    "split_base = 2\n",
    "min_samples_split_values = []\n",
    "for l in range(4,12):\n",
    "    param_int = int(split_base**l)\n",
    "    min_samples_split_values.append(param_int)\n",
    "    \n",
    "print(min_samples_split_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jackepstein/opt/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/jackepstein/opt/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/jackepstein/opt/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/jackepstein/opt/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/jackepstein/opt/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/jackepstein/opt/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/jackepstein/opt/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/jackepstein/opt/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/jackepstein/opt/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/jackepstein/opt/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/jackepstein/opt/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/jackepstein/opt/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/jackepstein/opt/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Code here\n",
    "\n",
    "#store a dictionary rather than the lists -- make it easier to plot after\n",
    "recalls = {}\n",
    "aucs = {}\n",
    "#loop through the sample splits and create a list for each\n",
    "for l in min_samples_leaf_values:\n",
    "    recalls[l] = list()\n",
    "    aucs[l] = list()\n",
    "    \n",
    "    #loop within one sample split, loop through the leaf sizes to get a different score\n",
    "    for s in min_samples_split_values:\n",
    "        \n",
    "        clf = DecisionTreeClassifier(criterion='entropy', min_samples_leaf=l, min_samples_split=s)\n",
    "        clf = clf.fit(X_train, Y_train_cl)\n",
    "        aucs[l].append(roc_auc_score(y_true, clf.predict(X_test)))\n",
    "        recall = classification_report(y_true, clf.predict(X_test), output_dict=True)['1']['recall']\n",
    "        recalls[l].append(recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 0.31545338441890164\n",
      "4 0.3282247765006386\n",
      "8 0.3231162196679438\n",
      "16 0.27330779054916987\n",
      "32 0.26181353767560667\n",
      "64 0.26053639846743293\n",
      "128 0.26053639846743293\n",
      "256 0.17752234993614305\n",
      "512 0.11877394636015326\n",
      "1024 0.0\n"
     ]
    }
   ],
   "source": [
    "#check recalls\n",
    "for k in recalls.keys():\n",
    "    print(k,max(recalls[k]))     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#re-run on best parameters and get this feature importance\n",
    "#use leaf size=2, split size=32\n",
    "clf_full_best = DecisionTreeClassifier(criterion='entropy', \n",
    "                                       min_samples_leaf=2, min_samples_split=32).fit(X_train, Y_train_cl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get features\n",
    "features_clf = pd.DataFrame()\n",
    "features_clf['col'] = X_test.columns\n",
    "features_clf['feature_importance'] = clf_full_best.feature_importances_\n",
    "top_15_feats = features_clf.sort_values(by=['feature_importance'], ascending=False).head(15)['col'].to_list()\n",
    "fea = features_clf.sort_values(by=['feature_importance'], ascending=False)\n",
    "fea.to_csv('featureimportance_DT.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Decision Tree -- top 15 features (based on baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate slimmed training data set\n",
    "X_train_topdf = X_train[top_15_feats]\n",
    "X_test_topdf = X_test[top_15_feats]\n",
    "\n",
    "\n",
    "#generate slimmed training data set\n",
    "X_train_toprf = X_train[top_feats_rf]\n",
    "X_test_toprf = X_test[top_feats_rf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jackepstein/opt/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/jackepstein/opt/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/jackepstein/opt/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/jackepstein/opt/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/jackepstein/opt/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/jackepstein/opt/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/jackepstein/opt/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/jackepstein/opt/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/jackepstein/opt/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/jackepstein/opt/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/jackepstein/opt/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/jackepstein/opt/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/jackepstein/opt/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/jackepstein/opt/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/jackepstein/opt/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/jackepstein/opt/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/jackepstein/opt/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Code here\n",
    "\n",
    "#store a dictionary rather than the lists -- make it easier to plot after\n",
    "recalls_top = {}\n",
    "#loop through the sample splits and create a list for each\n",
    "for l in min_samples_leaf_values:\n",
    "    recalls_top[l] = list()\n",
    "    \n",
    "    #loop within one sample split, loop through the leaf sizes to get a different score\n",
    "    for s in min_samples_split_values:\n",
    "        \n",
    "        clf = DecisionTreeClassifier(criterion='entropy', min_samples_leaf=l, min_samples_split=s)\n",
    "        clf = clf.fit(X_train_topdf, Y_train_cl)\n",
    "        recall = classification_report(y_true, clf.predict(X_test_topdf), output_dict=True)['1']['recall']\n",
    "        recalls_top[l].append(recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 0.24265644955300128\n",
      "4 0.26181353767560667\n",
      "8 0.2962962962962963\n",
      "16 0.21583652618135377\n",
      "32 0.22094508301404853\n",
      "64 0.21583652618135377\n",
      "128 0.21583652618135377\n",
      "256 0.1966794380587484\n",
      "512 0.11877394636015326\n",
      "1024 0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.22988505747126436,\n",
       " 0.24265644955300128,\n",
       " 0.21583652618135377,\n",
       " 0.210727969348659,\n",
       " 0.12260536398467432,\n",
       " 0.14559386973180077,\n",
       " 0.21583652618135377,\n",
       " 0.0]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check recalls\n",
    "for k in recalls_top.keys():\n",
    "    print(k,max(recalls_top[k]))\n",
    "    \n",
    "recalls_top[2]    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Decision Tree -- top 15 features (based on RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jackepstein/opt/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/jackepstein/opt/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/jackepstein/opt/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/jackepstein/opt/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/jackepstein/opt/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/jackepstein/opt/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/jackepstein/opt/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/jackepstein/opt/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/jackepstein/opt/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/jackepstein/opt/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/jackepstein/opt/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/jackepstein/opt/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/jackepstein/opt/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/jackepstein/opt/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/jackepstein/opt/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/jackepstein/opt/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/jackepstein/opt/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Code here\n",
    "\n",
    "#store a dictionary rather than the lists -- make it easier to plot after\n",
    "recalls_top2 = {}\n",
    "#loop through the sample splits and create a list for each\n",
    "for l in min_samples_leaf_values:\n",
    "    recalls_top2[l] = list()\n",
    "    \n",
    "    #loop within one sample split, loop through the leaf sizes to get a different score\n",
    "    for s in min_samples_split_values:\n",
    "        \n",
    "        clf = DecisionTreeClassifier(criterion='entropy', min_samples_leaf=l, min_samples_split=s)\n",
    "        clf = clf.fit(X_train_toprf, Y_train_cl)\n",
    "        recall = classification_report(y_true, clf.predict(X_test_toprf), output_dict=True)['1']['recall']\n",
    "        recalls_top2[l].append(recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 0.24265644955300128\n",
      "4 0.26181353767560667\n",
      "8 0.2962962962962963\n",
      "16 0.21583652618135377\n",
      "32 0.22094508301404853\n",
      "64 0.21583652618135377\n",
      "128 0.21583652618135377\n",
      "256 0.1966794380587484\n",
      "512 0.11877394636015326\n",
      "1024 0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.22988505747126436,\n",
       " 0.24265644955300128,\n",
       " 0.21583652618135377,\n",
       " 0.210727969348659,\n",
       " 0.12260536398467432,\n",
       " 0.14559386973180077,\n",
       " 0.21583652618135377,\n",
       " 0.0]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check recalls\n",
    "for k in recalls_top.keys():\n",
    "    print(k,max(recalls_top[k]))\n",
    "    \n",
    "    \n",
    "recalls_top[2]    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Multi-Class Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on results above, will use all features and winning hyperparameters (min_leaf=2, min_split=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(criterion='entropy', min_samples_leaf=2,\n",
       "                       min_samples_split=32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fit the model\n",
    "clf_size = DecisionTreeClassifier(min_samples_leaf=2, min_samples_split=32, criterion='entropy')\n",
    "clf_size.fit(X_train, Y_train_cl_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5274  133   64   82]\n",
      " [ 329   31   13   26]\n",
      " [ 129   12    4   19]\n",
      " [ 162   14    6   38]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.95      0.92      5553\n",
      "           1       0.16      0.08      0.11       399\n",
      "           2       0.05      0.02      0.03       164\n",
      "           3       0.23      0.17      0.20       220\n",
      "\n",
      "    accuracy                           0.84      6336\n",
      "   macro avg       0.33      0.31      0.31      6336\n",
      "weighted avg       0.80      0.84      0.82      6336\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#turn truth and predictions into arrays\n",
    "y_test_size_arr = Y_test_cl_size.to_numpy().ravel()\n",
    "preds_size = clf_size.predict(X_test)\n",
    "\n",
    "\n",
    "print(confusion_matrix(y_test_size_arr, preds_size))\n",
    "\n",
    "\n",
    "print(classification_report(y_test_size_arr, preds_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_size.feature_importances_\n",
    "#get features\n",
    "features_clf_size = pd.DataFrame()\n",
    "features_clf_size['col'] = X_test.columns\n",
    "features_clf_size['feature_importance'] = clf_size.feature_importances_\n",
    "feats = features_clf_size.sort_values(by=['feature_importance'], ascending=False)\n",
    "feats.to_csv('featureimportance_DT_size.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
