{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, multilabel_confusion_matrix\n",
    "from sklearn.metrics import auc, roc_curve, r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.preprocessing import scale, label_binarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  # provides interface for interacting with tabular data\n",
    "import geopandas as gpd  # combines the capabilities of pandas and shapely for geospatial operations\n",
    "from shapely.geometry import Point, Polygon, MultiPolygon  # for manipulating text data into geospatial shapes\n",
    "from shapely import wkt  # stands for \"well known text,\" allows for interchange across GIS programs\n",
    "import rtree  # supports geospatial join\n",
    "import os\n",
    "import fnmatch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import descartes\n",
    "import sys\n",
    "import sklearn\n",
    "from shapely.ops import nearest_points\n",
    "from datetime import datetime as dt, date\n",
    "sys.path.append('C:/Users/jades/1001 Intro to Data Science Notebooks/Project/wildfires-1001/code/functions/')\n",
    "from gis_processing import *\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "git_dir = 'C:/Users/jades/1001 Intro to Data Science Notebooks/Project/wildfires-1001/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_rename_dict = pd.read_pickle(os.path.join(git_dir, 'data/clean_data/ERA_weather-data/ERA_rename_dictionary.pkl'))\n",
    "mod_lr = pd.read_pickle(os.path.join(git_dir, 'models/LR_30entropy_1990_2015.pkl'))\n",
    "mod_svm = pd.read_pickle(os.path.join(git_dir, 'models/linSVC_30entropy_1990_2015_a.pkl'))\n",
    "feat_list = pd.read_pickle(os.path.join(git_dir, 'models/feature_lists/RF_entropy_top30_features.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_df1 = pd.read_pickle(os.path.join(git_dir, 'data/clean_data/target_df_final_1123_newtargets_1.pkl'))\n",
    "target_df2 = pd.read_pickle(os.path.join(git_dir, 'data/clean_data/target_df_final_1123_newtargets_2.pkl'))\n",
    "target_df = target_df1.append(target_df2)\n",
    "target_df.rename(columns = weather_rename_dict, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_mod_cols = ['GRID_ID','month_id','MONTH','COUNTYFP','COUNTY_AREA', 'NAME','GRID_AREA','COUNTY_ARE','month_id_old_x','month_id_old_y',\n",
    "                'geometry','Fire_area','total_fire_days','hist_p_time_1y','total_fire_days','hist_p_time_1y', \n",
    "                'hist_p_time_1m', 'month_id_old', 'YEAR']\n",
    "Y_cols = ['Y_bin', 'Y_fire_count', 'Y_fire_area_prop', 'Y_fire_class_size','Y_bin_new_fire_month',\n",
    "          'Y_max_new_fire_size_month','Y_count_new_fires_month']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary Target Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_stage1_data = target_df[(target_df['YEAR']>1989) & (target_df['YEAR']<=2005)]\n",
    "X_train_stage1 = train_stage1_data.drop('YEAR', axis = 1)\n",
    "for y in Y_cols + non_mod_cols:\n",
    "    try:\n",
    "        X_train_stage1.drop(y, inplace = True, axis =1)\n",
    "    except:\n",
    "        pass\n",
    "Y_train_stage1_bin = train_stage1_data['Y_bin_new_fire_month'].to_frame()\n",
    "Y_train_stage1_area = train_stage1_data['Y_fire_area_prop'].to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_stage2_data = target_df[(target_df['YEAR']>2005) & (target_df['YEAR']<=2016)]\n",
    "X_train_stage2 = train_stage2_data.drop('YEAR', axis = 1)\n",
    "for y in Y_cols + non_mod_cols:\n",
    "    try:\n",
    "        X_train_stage2.drop(y, inplace = True, axis =1)\n",
    "    except:\n",
    "        pass\n",
    "Y_train_stage2_bin = train_stage2_data['Y_bin_new_fire_month'].to_frame()\n",
    "Y_train_stage2_area = train_stage2_data['Y_fire_area_prop'].to_frame() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = target_df[target_df['YEAR']>2016]\n",
    "X_test = test_data.drop('YEAR', axis = 1)\n",
    "for y in Y_cols + non_mod_cols:\n",
    "    try:\n",
    "        X_test.drop(y, inplace = True, axis =1)\n",
    "    except:\n",
    "        pass\n",
    "Y_test_bin = test_data['Y_bin_new_fire_month'].to_frame()\n",
    "Y_test_area = test_data['Y_fire_area_prop'].to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_stage1_scaled = pd.DataFrame(scale(X_train_stage1), columns = X_train_stage1.columns)\n",
    "X_train_stage2_scaled = pd.DataFrame(scale(X_train_stage2), columns = X_train_stage2.columns)\n",
    "X_test_scaled = pd.DataFrame(scale(X_test), columns = X_test.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Classification Model Using First Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.001, class_weight='balanced')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod_lr = LogisticRegression(C=0.001, class_weight='balanced')\n",
    "mod_lr.fit(X_train_stage1_scaled[feat_list], Y_train_stage1_bin['Y_bin_new_fire_month'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=0.0001, class_weight='balanced', dual=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#mod_lr = LinearSVC(C=0.0001, class_weight='balanced', dual=False)\n",
    "#mod_lr.fit(X_train_stage1_scaled[feat_list], Y_train_stage1_bin['Y_bin_new_fire_month'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(git_dir, 'models/linSVC_30entropy_1990_2005.pkl'), 'wb') as handle:\n",
    "    pickle.dump(mod_lr, handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Input for Regression Model Using Second Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_stage1 = mod_lr.predict(X_train_stage2_scaled[feat_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_stage2['preds_stage1'] = preds_stage1\n",
    "Y_train_stage2_area['preds_stage1'] = preds_stage1\n",
    "\n",
    "X_train_stage2 = X_train_stage2[X_train_stage2['preds_stage1'] == 1]\n",
    "Y_train_stage2_area = Y_train_stage2_area[Y_train_stage2_area['preds_stage1'] == 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Regression Model Using Filtered Second Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit model\n",
    "mod_linr = LinearRegression()\n",
    "mod_linr.fit(X_train_stage2[feat_list], Y_train_stage2_area['Y_fire_area_prop'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Input for Regression Model Using Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict using stage 1 model to identify positive instances\n",
    "preds_stage1 = mod_lr.predict(X_test_scaled[feat_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a filtered test df of just the instances flagged as positive from the stage 1 model\n",
    "X_test['preds_stage1'] = preds_stage1\n",
    "Y_test_area['preds_stage1'] = preds_stage1\n",
    "\n",
    "X_test_filtered = X_test[X_test['preds_stage1'] == 1]\n",
    "Y_test_filtered_area = Y_test_area[Y_test_area['preds_stage1'] == 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score Regression Model on Filtered Test and Full Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3132056335984441"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Score on the instances flagged as positive from the stage 1 model\n",
    "preds_stage2 = mod_linr.predict(X_test_filtered[feat_list])\n",
    "r2_score(Y_test_filtered_area['Y_fire_area_prop'], preds_stage2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-83-c8d2bb730673>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test_filtered['preds_stage2'] = preds_stage2\n"
     ]
    }
   ],
   "source": [
    "# Join our predictions back on the full test df and null fill with 0s (we predict an area of 0 if the stage 1 model predicts 0)\n",
    "X_test_filtered['preds_stage2'] = preds_stage2\n",
    "\n",
    "X_test = X_test.merge(X_test_filtered['preds_stage2'], how='left', left_index=True, right_index=True)\n",
    "X_test['preds_stage2'] = X_test['preds_stage2'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23220533515415043"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Score on all test instances\n",
    "r2_score(Y_test_area['Y_fire_area_prop'], X_test['preds_stage2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate\n",
    "# 1. Use different train data set\n",
    "# 2. Use random forest\n",
    "# 3. Iterate on linear regression parameters\n",
    "# 4. Iterate on features used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stage 1: LR, Stage 2: Linear Reg, Train: 1990-2015\n",
    "# Filtered test preds: 0.3499442581817819\n",
    "# Full test preds: 0.2542595355564937\n",
    "\n",
    "# Stage 1: LR, Stage 2: Linear Reg, Train: 1990-2005\n",
    "# Filtered test preds: 0.2845267658849393\n",
    "# Full test preds: 0.17590153864987512\n",
    "\n",
    "# Stage 1: SVM, Stage 2: Linear Reg, Train: 1990-2015\n",
    "# Filtered test preds: 0.43705572076979404\n",
    "# Full test preds: 0.3723310731845757\n",
    "\n",
    "# Stage 1: SVM, Stage 2: Linear Reg, Train: 1990-2005\n",
    "# Filtered test preds: 0.26957720030158305\n",
    "# Full test preds: 0.16976467996687516"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
